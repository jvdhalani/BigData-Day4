{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement:**\n",
    "\n",
    "Using a dataset of collection of SMS, predict whether a piece of text/sms is a Spam or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the dataset into a Spark Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import SQLContext\n",
    "# sqlContext = SQLContext(sc)\n",
    "\n",
    "# spark = SparkSession \\\n",
    "#     .builder \\\n",
    "#     .appName(\"Python Spark dataframe basic example\") \\\n",
    "#     .getOrCreate()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "data = spark.read.csv('../data/SMSSpamCollection.csv', header='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category', 'text']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's have a look to our Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|category|                text|\n",
      "+--------+--------------------+\n",
      "|     ham|Go until jurong p...|\n",
      "|     ham|Ok lar... Joking ...|\n",
      "|    spam|Free entry in 2 a...|\n",
      "|     ham|U dun say so earl...|\n",
      "|     ham|Nah I don't think...|\n",
      "|    spam|FreeMsg Hey there...|\n",
      "|     ham|Even my brother i...|\n",
      "|     ham|As per your reque...|\n",
      "|    spam|WINNER!! As a val...|\n",
      "|    spam|Had your mobile 1...|\n",
      "|     ham|I'm gonna be home...|\n",
      "|    spam|SIX chances to wi...|\n",
      "|    spam|URGENT! You have ...|\n",
      "|     ham|I've been searchi...|\n",
      "|     ham|I HAVE A DATE ON ...|\n",
      "|    spam|XXXMobileMovieClu...|\n",
      "|     ham|Oh k...i'm watchi...|\n",
      "|     ham|Eh u remember how...|\n",
      "|     ham|Fine if that¬ís t...|\n",
      "|    spam|England v Macedon...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the schema to see datatype of each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count number of messages in each catergory present into our dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|category|count|\n",
      "+--------+-----+\n",
      "|     ham| 4827|\n",
      "|    spam|  747|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# by top 20 categories\n",
    "data.groupBy(\"category\") \\\n",
    "    .count() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross checking with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/SMSSpamCollection.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4827\n",
       "spam     747\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, perform three tasks:**\n",
    "\n",
    "1. Prepare your data i.e. `text` column by tokenizing the words\n",
    "2. Remove stop words from the tokenized column\n",
    "3. Finally Bag of words i.e. CountVectorizer to get features\n",
    "\n",
    "\n",
    "Use official documentation guide Spark on MLlib to solve the exercise. Link:\n",
    "\n",
    "[Spark MLlib guide](http://spark.apache.org/docs/1.6.2/ml-features.html#vectorassembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# regular expression tokenizer\n",
    "#regexTokenizer = RegexTokenizer()\n",
    "\n",
    "# stop words\n",
    "#add_stopwords = stopwords.words('english')\n",
    "\n",
    "#stopwordsRemover = StopWordsRemover().setStopWords(add_stopwords)\n",
    "\n",
    "# bag of words count\n",
    "#countVectors = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Apply StringIndexer to the `category` column to get label indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "# String Indexer - A label indexer that maps a string column of labels to an ML column of label indices.\n",
    "\n",
    "# label_stringIdx = StringIndexer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline All the steps performed above upsing Spark Pipeline API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n",
    "\n",
    "# pipeline = Pipeline(stages=[])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "# pipelineFit = pipeline.fit()\n",
    "# dataset = pipelineFit.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `show()` to have a look to your transformed dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, split the dataset into training and test data**\n",
    "\n",
    "**Also, count the number of rows into each dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "\n",
    "# (trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "# print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "# print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using Count Vector Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Logisitic Regression using Count Vector Features generated and train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "# lr = LogisticRegression()\n",
    "\n",
    "# Train model with Training Data\n",
    "\n",
    "# lrModel = lr.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform prediction using the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = lrModel.transform()\n",
    "\n",
    "# predictions.filter(predictions['prediction'] == 0) \\\n",
    "#     .select(\"text\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "#     .orderBy(\"probability\", ascending=False) \\\n",
    "#     .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform evaluations using MulticlassClassificationEvaluator**\n",
    "\n",
    "Hint: Use MulticlassClassificationEvaluator\n",
    "`from pyspark.ml.evaluation import MulticlassClassificationEvaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# evaluator = MulticlassClassificationEvaluator()\n",
    "# evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using TF-IDF Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, Apply Logistic Regression using TF-IDF to see if we can improve the accuracy further**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "# Add HashingTF and IDF to transformation\n",
    "# hashingTF = HashingTF(inputCol=\"\", outputCol=\"\", numFeatures=10000)\n",
    "# idf = IDF(inputCol=\"\", outputCol=\"\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "# # Redo Pipeline\n",
    "# pipeline = Pipeline(stages=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "\n",
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "# (trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "# # Build the model\n",
    "# lr = LogisticRegression()\n",
    "\n",
    "# # Train model with Training Data\n",
    "# lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform predictions on Testdata using this model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = lrModel.transform()\n",
    "\n",
    "# predictions.filter(predictions['prediction'] == 0) \\\n",
    "#     .select(\"text\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "#     .orderBy(\"probability\", ascending=False) \\\n",
    "#     .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate your model using MulticlassClassificationEvaluator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator = MulticlassClassificationEvaluator(predictionCol=\"\")\n",
    "# evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give a custom message to your trained model and check results. Remember, feed your text in form of dataframe to the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of how to create a spark dataframe\n",
    "\n",
    "```python\n",
    "from pyspark.sql import Row\n",
    "l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\n",
    "rdd = sc.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "schemaPeople = sqlContext.createDataFrame(people)\n",
    "\n",
    "print(type(schemaPeople))\n",
    "#  pyspark.sql.dataframe.DataFrame\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "ll = [('Hurry up! Answer simple questions and WINNER will get $900 prize reward! To claim call us. Valid 12 hours only.'),('Hey, How are you? Long time no see')]\n",
    "rdds = sc.parallelize(ll)\n",
    "tx = rdds.map(lambda x: Row(text=x))\n",
    "schematxt = sqlContext.createDataFrame(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Hurry up! Answer ...|\n",
      "|Hey, How are you?...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schematxt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating features for test sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|            filtered|         rawFeatures|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Hurry up! Answer ...|[hurry, up, answe...|[hurry, answer, s...|(10000,[1,721,727...|(10000,[1,721,727...|\n",
      "|Hey, How are you?...|[hey, how, are, y...|[hey, long, time,...|(10000,[7515,8157...|(10000,[7515,8157...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test_new_dataset = pipelineFit.transform()\n",
    "# test_new_dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on calculated features of test sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred = lrModel.transform(test_new_dataset)\n",
    "\n",
    "# test_pred.filter(test_pred['prediction'] == 0) \\\n",
    "#     .select(\"text\",\"probability\",\"prediction\") \\\n",
    "#     .orderBy(\"probability\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|                text|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|Hurry up! Answer ...|[0.40530136808716...|       1.0|\n",
      "|Hey, How are you?...|[0.96833775344934...|       0.0|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test_pred.select(\"text\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model using Naive Bayes algorithm\n",
    "\n",
    "### Predict on sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "# nb = NaiveBayes()\n",
    "# model = nb.fit()\n",
    "# predictions = model.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator = MulticlassClassificationEvaluator()\n",
    "# evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction on sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred.select(\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see Naive Bayes performed well and it's able to identify message as spam! Congrats!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also you could try Random Forest. See how well it's performing?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
