{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import SQLContext\n",
    "# sqlContext = SQLContext(sc)\n",
    "from pyspark.sql import SparkSession\n",
    "# spark = SparkSession \\\n",
    "#     .builder \\\n",
    "#     .appName(\"Python Spark dataframe basic example\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "data = spark.read.csv('../data/SMSSpamCollection.csv', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category', 'text']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|category|                text|\n",
      "+--------+--------------------+\n",
      "|     ham|Go until jurong p...|\n",
      "|     ham|Ok lar... Joking ...|\n",
      "|    spam|Free entry in 2 a...|\n",
      "|     ham|U dun say so earl...|\n",
      "|     ham|Nah I don't think...|\n",
      "|    spam|FreeMsg Hey there...|\n",
      "|     ham|Even my brother i...|\n",
      "|     ham|As per your reque...|\n",
      "|    spam|WINNER!! As a val...|\n",
      "|    spam|Had your mobile 1...|\n",
      "|     ham|I'm gonna be home...|\n",
      "|    spam|SIX chances to wi...|\n",
      "|    spam|URGENT! You have ...|\n",
      "|     ham|I've been searchi...|\n",
      "|     ham|I HAVE A DATE ON ...|\n",
      "|    spam|XXXMobileMovieClu...|\n",
      "|     ham|Oh k...i'm watchi...|\n",
      "|     ham|Eh u remember how...|\n",
      "|     ham|Fine if that¬ís t...|\n",
      "|    spam|England v Macedon...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|category|count|\n",
      "+--------+-----+\n",
      "|     ham| 4827|\n",
      "|    spam|  747|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# by top 20 categories\n",
    "data.groupBy(\"category\") \\\n",
    "    .count() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross checking with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/SMSSpamCollection.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4827\n",
       "spam     747\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, perform three tasks:**\n",
    "\n",
    "1. Prepare your data i.e. `text` column by tokenizing the words\n",
    "2. Remove stop words from the tokenized column\n",
    "3. Finally Bag of words i.e. CountVectorizer to get features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# stop words\n",
    "add_stopwords = stopwords.words('english')\n",
    "\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Apply StringIndexer to the `category` column to get label indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "# String Indexer - A label indexer that maps a string column of labels to an ML column of label indices.\n",
    "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline All the steps performed above upsing Spark Pipeline API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|category|                text|               words|            filtered|            features|label|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|     ham|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|(1714,[10,14,35,5...|  0.0|\n",
      "|     ham|Ok lar... Joking ...|[ok, lar, joking,...|[ok, lar, joking,...|(1714,[0,8,247,36...|  0.0|\n",
      "|    spam|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|(1714,[2,9,21,22,...|  1.0|\n",
      "|     ham|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|(1714,[0,53,78,79...|  0.0|\n",
      "|     ham|Nah I don't think...|[nah, i, don, t, ...|[nah, think, goes...|(1714,[49,131,361...|  0.0|\n",
      "|    spam|FreeMsg Hey there...|[freemsg, hey, th...|[freemsg, hey, da...|(1714,[8,13,19,24...|  1.0|\n",
      "|     ham|Even my brother i...|[even, my, brothe...|[even, brother, l...|(1714,[13,123,279...|  0.0|\n",
      "|     ham|As per your reque...|[as, per, your, r...|[per, request, me...|(1714,[144,156,29...|  0.0|\n",
      "|    spam|WINNER!! As a val...|[winner, as, a, v...|[winner, valued, ...|(1714,[1,60,75,14...|  1.0|\n",
      "|    spam|Had your mobile 1...|[had, your, mobil...|[mobile, 11, mont...|(1714,[0,1,9,29,4...|  1.0|\n",
      "|     ham|I'm gonna be home...|[i, m, gonna, be,...|[gonna, home, soo...|(1714,[20,27,30,3...|  0.0|\n",
      "|    spam|SIX chances to wi...|[six, chances, to...|[six, chances, wi...|(1714,[5,15,19,22...|  1.0|\n",
      "|    spam|URGENT! You have ...|[urgent, you, hav...|[urgent, 1, week,...|(1714,[9,22,24,51...|  1.0|\n",
      "|     ham|I've been searchi...|[i, ve, been, sea...|[searching, right...|(1714,[42,77,143,...|  0.0|\n",
      "|     ham|I HAVE A DATE ON ...|[i, have, a, date...|      [date, sunday]|(1714,[475,676],[...|  0.0|\n",
      "|    spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(1714,[22,35,74,1...|  1.0|\n",
      "|     ham|Oh k...i'm watchi...|[oh, k, i, m, wat...|   [oh, k, watching]|(1714,[39,59,273]...|  0.0|\n",
      "|     ham|Eh u remember how...|[eh, u, remember,...|[eh, u, remember,...|(1714,[0,2,66,69,...|  0.0|\n",
      "|     ham|Fine if that¬ís t...|[fine, if, that, ...|[fine, way, u, fe...|(1714,[0,68,85,12...|  0.0|\n",
      "|    spam|England v Macedon...|[england, v, mace...|[england, v, mace...|(1714,[4,22,24,40...|  1.0|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, split the dataset into training and test data**\n",
    "\n",
    "**Also, count the number of rows into each dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3964\n",
      "Test Dataset Count: 1610\n"
     ]
    }
   ],
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using Count Vector Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Logisitic Regression using Count Vector Features generated and train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform prediction using the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                          text|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|The last thing i ever wante...|     ham|[0.9936283579085395,0.00637...|  0.0|       0.0|\n",
      "|He neva grumble but i sad l...|     ham|[0.9903902270119437,0.00960...|  0.0|       0.0|\n",
      "|Oh... Haha... Den we shld h...|     ham|[0.9893446221699386,0.01065...|  0.0|       0.0|\n",
      "|Heart is empty without love...|     ham|[0.9877406605014499,0.01225...|  0.0|       0.0|\n",
      "|Havent planning to buy late...|     ham|[0.9872145503164064,0.01278...|  0.0|       0.0|\n",
      "|Wen ur lovable bcums angry ...|     ham|[0.9870260688139731,0.01297...|  0.0|       0.0|\n",
      "|THING R GOOD THANX GOT EXAM...|     ham|[0.9868148796206359,0.01318...|  0.0|       0.0|\n",
      "|Sounds like there could be ...|     ham|[0.9861182389194111,0.01388...|  0.0|       0.0|\n",
      "|Although i told u dat i'm i...|     ham|[0.9858574802491821,0.01414...|  0.0|       0.0|\n",
      "|House-Maid is the murderer,...|     ham|[0.9849858120732038,0.01501...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform evaluations using MulticlassClassificationEvaluator**\n",
    "Hint: Use MulticlassClassificationEvaluator\n",
    "`from pyspark.ml.evaluation import MulticlassClassificationEvaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645509258772988"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using TF-IDF Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, Apply Logistic Regression using TF-IDF to see if we can improve the accuracy further**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "# Add HashingTF and IDF to transformation\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "# Redo Pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "\n",
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "# Build the model\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                          text|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|THING R GOOD THANX GOT EXAM...|     ham|[0.9894476412953456,0.01055...|  0.0|       0.0|\n",
      "|He neva grumble but i sad l...|     ham|[0.9887095930738091,0.01129...|  0.0|       0.0|\n",
      "|Although i told u dat i'm i...|     ham|[0.9877546446366153,0.01224...|  0.0|       0.0|\n",
      "|Wen ur lovable bcums angry ...|     ham|[0.9873871799731352,0.01261...|  0.0|       0.0|\n",
      "|\"And that is the problem. Y...|     ham|[0.9870440089341924,0.01295...|  0.0|       0.0|\n",
      "|U say leh... Of course noth...|     ham|[0.9870247728278815,0.01297...|  0.0|       0.0|\n",
      "|Honeybee Said: *I'm d Sweet...|     ham|[0.9865047862576719,0.01349...|  0.0|       0.0|\n",
      "|Cos i was out shopping wif ...|     ham|[0.986161453417046,0.013838...|  0.0|       0.0|\n",
      "|Hi neva worry bout da truth...|     ham|[0.9861233055662262,0.01387...|  0.0|       0.0|\n",
      "|Yar he quite clever but aft...|     ham|[0.9857146230961832,0.01428...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645509258772988"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give a custom message to your trained model and check results. Remember, feed your text in form of dataframe to the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of how to create a spark dataframe\n",
    "\n",
    "```python\n",
    "from pyspark.sql import Row\n",
    "l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\n",
    "rdd = sc.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "schemaPeople = sqlContext.createDataFrame(people)\n",
    "\n",
    "print(type(schemaPeople))\n",
    "#  pyspark.sql.dataframe.DataFrame\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "ll = [('Hurry up! Answer simple questions and WINNER will get $900 prize reward! To claim call us. Valid 12 hours only.'),('Hey, How are you? Long time no see')]\n",
    "rdds = sc.parallelize(ll)\n",
    "tx = rdds.map(lambda x: Row(text=x))\n",
    "schematxt = sqlContext.createDataFrame(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Hurry up! Answer ...|\n",
      "|Hey, How are you?...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schematxt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating features for test sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|            filtered|         rawFeatures|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Hurry up! Answer ...|[hurry, up, answe...|[hurry, answer, s...|(10000,[1,721,727...|(10000,[1,721,727...|\n",
      "|Hey, How are you?...|[hey, how, are, y...|[hey, long, time,...|(10000,[7515,8157...|(10000,[7515,8157...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_new_dataset = pipelineFit.transform(schematxt)\n",
    "test_new_dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on calculated features of test sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lrModel.transform(test_new_dataset)\n",
    "# test_pred.filter(test_pred['prediction'] == 0) \\\n",
    "#     .select(\"text\",\"probability\",\"prediction\") \\\n",
    "#     .orderBy(\"probability\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|                text|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|Hurry up! Answer ...|[0.40530136808716...|       1.0|\n",
      "|Hey, How are you?...|[0.96833775344934...|       0.0|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred.select(\"text\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model using Naive Bayes algorithm\n",
    "\n",
    "### Predict on sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731847068395234"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction on sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|                text|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|Hurry up! Answer ...|[0.40530136808716...|       1.0|\n",
      "|Hey, How are you?...|[0.96833775344934...|       0.0|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred.select(\"text\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see Naive Bayes performed well and it's able to identify message as spam! Congrats!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also you could try Random Forest. See how well it's performing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
